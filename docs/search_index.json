[
["index.html", "POLS0008: Introduction to Quantitative Research Methods Welcome Moodle Important Office hours", " POLS0008: Introduction to Quantitative Research Methods Justin van Dijk1, Stephen Jivraj2, and James Cheshire3 2021-01-05 Welcome Welcome to Introduction to Quantitative Research Methods, one of the first year core module for students enrolled on Q-Step programmes and a second year methods option in BSc Philosophy, Politics and Economics. Moodle All important information and communication in relation to this module will be provided on Moodle. Although for the first 4 weeks all short lecture videos and practical materials will be hosted on this webpage, do check on Moodle regularly to see if there are any updates and to access the POLS0008 Forum to ask and answer questions. Important We do not offer any technical support. If you have any technical questions or encounter technical problems, you will have to take this up with the IT Service Desk. Similarly, for questions related to the organisation of the course (e.g. in which seminar group your get assigned to), you will have to direct your queries to the student office of your Department. Office hours Office hours with Dr Justin van Dijk (Tuesdays between 15h00 and 16h00) can be booked here. Office hours with Dr Stephen Jivraj (Tuesdays between 09h45 and 10h45) can be booked here. Department of Geography, https://www.mappingdutchman.com/↩︎ Institute of Epidemiology and Health Care, https://www.ucl.ac.uk/q-step/stephen-jivraj↩︎ Department of Geography, http://jcheshire.com↩︎ "],
["understanding-data.html", "1 Understanding data 1.1 Introduction 1.2 R 1.3 Statistical terminology 1.4 Descriptive statistics 1.5 Seminar 1.6 Before you leave", " 1 Understanding data 1.1 Introduction Welcome to your first week of Introduction to Quantitative Research Methods. This week we will focus on understanding data. Some of you may wonder why it is necessary to take acourse on data and statistics in the first place? There are several compelling reasons to have a (basic) knowledge of data and statistics: it will help you to understand and critically engage with academic articles; it will help you critically assess statistics used in the media, government reports, etc.; it will help you write a dissertation based on secondary analysis; it will help you write your own work convicingly. Further to this, data skills are in high demand by employers both in the public and private sectors. TL;DR: Having a basic understanding of data and statistics is essential both during and after your time at University. 1.1.1 Reading list For this week, you will have to read the following book Chapters: Lane et al., 2003, Chapter 1: Introduction. In: Lane et al., 2003, Introduction to Statistics. Houston, Texas: Rice University. 1.1.2 Video: Overview [Lecture slides] [Watch on MS stream] 1.2 R Arguably the easiest way to start learning about data is by getting your hands dirty So, before we will introduce you to some statistical terminology and talk about something called descriptive statistics, we will have a look at one of the software tools with which we will be working this semester: R. R is a free software environment for statistical computing and graphics. It is extremely powerful and as such is now widely used for academic research as well as in the commercial sector. Ever wondered what tool is used to create those excellent coronavirus visualisations in the Financial Times? 1.2.1 Video: R [Lecture slides] [Watch on MS stream] Unlike software programmes such as Microsoft Excel or SPSS, within a coding environment the user has to type commands to get it to execute tasks such as loading in a dataset or performing a calculation. The biggest advantage of this approach is that you can build up a document, or script, that provides a record of what you have done, which in turn enables the straightforward repetition of tasks. Graphics can be easily modified and tweaked by making slight changes to the script or by scrolling through past commands and making quick edits. Unfortunately, command-line computing can also be off-putting at first. It is easy to make mistakes that are not always obvious to detect. Nevertheless, there are good reasons to stick with R. These include: It’s broadly intuitive with a strong focus on publishable-quality graphics. It’s ‘intelligent’ and offers in-built good practice – it tends to stick to statistical conventions and present data in sensible ways. It’s free, cross-platform, customisable and extendable with a whole swathe of libraries (‘add ons’) including those for discrete choice, multilevel and longitudinal regression, and mapping, spatial statistics, spatial regression, and geostatistics. It is well respected and used at the world’s largest technology companies (including Google, Microsoft and Facebook, and at hundreds of other companies). It offers a transferable skill that shows to potential employers experience both of statistics and of computing. The intention of the practical elements of this week is to provide a thorough introduction to R to get you started: The basic programming principles behind R. Loading in data from csv files and subsetting it into smaller chunks. Calculating a number of descriptive statistics for data exploration and checking. Creating basic and more complex plots in order to visualise the distributions values within a dataset. R has a steep learning curve, but the benefits of using it are well worth the effort. Take your time and think through every piece of code you type in. The best way to learn R is to take the basic code provided in tutorials and experiment with changing parameters - such as the colour of points in a graph - to really get ‘under the hood’ of the software. Take lots of notes as you go along and if you are getting really frustrated take a break! 1.2.2 Getting started with R You can download and install R on your laptop but for the purposes of this course we would like you to use the version hosted on the UCL servers so that everyone participating in the course has access to the same version of the software. Open a web browser and navigate to: https://rstudio.rc.ucl.ac.uk/ Log in with your usual UCL username and password. You should see the RStudio interface appear. Please note: RStudio server will only work with an active VPN connection that links your personal computer into UCL’s network. Students in mainland may want to use UCL China Connect. Figure 1.1: The RStudio interface. If you managed to log onto RStudio server: brilliant, we are ready to go. At its absolute simplest R is a calculator, so let’s try adding some numbers by typing in the console window and hitting enter to execute the code: 4 + 10 ## [1] 14 You will notices that in the command line window, it will give you an answer directly (i.e. 14). These outputs of the command line window are shown as ## throughout this handbook and you do not need to type anything into the command line that follows ## (because it simply shows the result of a command!). Anything that appears as red in the command line means it is an error (or a warning) so you will likely need to correct your code. If you see a &gt; on the left it means you can type in your next line, a + means that you haven’t finished the previous line of code. As will become clear, + signs often appear if you don’t close brackets or you did not properly finish your command in a way that R expected. Rather than using numbers and values, it is often easier to assign numbers (or groups of them) a memorable name for easy reference later. In R terminology this is called creating an object and this is really important. Let’s try this: a &lt;- 4 b &lt;- 10 The &lt;- symbol is used to assign the value to the name, in the above we assigned the integer 4 to an object with the name a. Similarly, we assigned the integer 10 to an object with the name b To see what each object contains you can just type print(name of your object), so in our case: print(a) ## [1] 4 print(b) ## [1] 10 This may look trivial, but in fact it is extremely powerful as objects can be treated in the same way as the numbers they contain. For instance: a*b ## [1] 40 Or even used to create new objects: ab &lt;- a*b print(ab) ## [1] 40 You can generate a list of objects that are currently active using the ls() command. R stores objects in your computer’s RAM so they can be processed quickly. Without saving (we will come onto this below) these objects will be lost if you close R (or it crashes). ls() ## [1] &quot;a&quot; &quot;ab&quot; &quot;b&quot; You may wish to delete an object. This can be done using rm() with the name of the object in the brackets. For example: rm(ab) To confirm that your command has worked, just run the ls() command again: ls() ## [1] &quot;a&quot; &quot;b&quot; 1.3 Statistical terminology Let’s now take a short break from RStudio and have a look at some theory: the video below will introduce you to some essential statistical terminology. 1.3.1 Video: Essential statistical terminology [Lecture slides] [Watch on MS stream] Now we now a little more about variables, we can go back to RStudio. Until now our objects have been extremely simple integers (and you should now know what integers are!), but the real power of R comes when we can begin to execute functions on objects. Let’s check this out by firstly building a more complex object through the c() function. The c in the c() function means concatenate and essentially groups things together. Let’s create an object that contains the birth years of the six main characters in the popular American television sitcom Friends. friends_dob &lt;- c(1969,1967,1970,1968,1968,1967) Let’s check the results. print(friends_dob) ## [1] 1969 1967 1970 1968 1968 1967 Now, we can execute some statistical functions on this object such as calculating the mean() value, the median() value, and the range() of the data. mean(friends_dob) ## [1] 1968.167 median(friends_dob) ## [1] 1968 range(friends_dob) ## [1] 1967 1970 All functions need a series of arguments to be passed to them in order to work. These arguments are typed within the brackets and typically comprise the name of the object (in the examples above its the friends_dob) that contains the data followed by some parameters. The exact parameters required are listed in the functions help files. To find the help file for the function type ? followed by the function name, for example: ?mean All helpfiles will have a usage heading detailing the parameters required. In the case of the mean you can see it simply says mean(x, ...). In function helpfiles x will always refer to the object the function requires and, in the case of the mean, the ... refers to some optional arguments that we don’t need to worry about. When you are new to R the help files can seem pretty impenetrable (because they often are!). Up until relatively recently these were all people had to go on, but in recent years R has really taken off and so there are plenty of places to find help and tips. Google is best tool to use. When people are having problems they tend to post examples of their code online and then the R community will correct it. One of the best ways to solve a problem is to paste their correct code into your R command line window and then gradually change it for your data an purposes. The structure of the friends_dob object - essentially a group of numbers (integers!) - is known as a vector object in R. To build more complex objects that, for example, resemble a spreadsheet with multiple columns of data, it is possible to create a class of objects known as a data frame. This is probably the most commonly used class of object in R. We can create one here by combining two vectors. friends_characters &lt;- c(&#39;Monica&#39;,&#39;Ross&#39;,&#39;Rachel&#39;,&#39;Joey&#39;,&#39;Chandler&#39;,&#39;Phoebe&#39;) friends &lt;- data.frame(friends_characters,friends_dob) If you type print(friends) you will see our newly created data frame that consists of the first vector object (date of birth) and the second vector objects (names of characters). print(friends) ## friends_characters friends_dob ## 1 Monica 1969 ## 2 Ross 1967 ## 3 Rachel 1970 ## 4 Joey 1968 ## 5 Chandler 1968 ## 6 Phoebe 1967 Tips R is case sensitive so you need to make sure that you capitalise everything correctly if required. The spaces between the words don’t matter but the positions of the commas and brackets do. Remember, if you find the prompt, &gt;, is replaced with a + it is because the command is incomplete. If necessary, hit the escape (esc) key and try again. It is important to come up with good names for your objects. In the case of the friends_dob object we used a underscore to separate the words. It is good practice to keep the object names as short as posssible so we could have gone for FriendsDob or f_dob. Be aware: you cannot start an object name with a number! If you press the up arrow in the command line you will be able to edit the previous lines of code you inputted. Recap In this section you have: Entered your first commands into the R command line interface. Created objects in R. Created a vector of values (the friends_dob object). Executed some simple R functions. Created a data frame (called friends). 1.4 Descriptive statistics 1.4.1 Video: Descriptive statistics I [Lecture slides] [Watch on MS stream] Now we got introduced to descriptive statistics, we can go back to RStudio again. In the previous section, R may have seemed fairly labour-intensive. We had to enter all our data manually and each line of code had to be written into the command line. Fortunately this isn’t routinely the case. In RStudio look to the top left corner and you will see a plus symbol, click on it and select R Script. Figure 1.2: Opening a new script in RStudio. This should give you a blank document that looks a bit like the command line. The difference is that anything you type here can be saved as a script and re-run at a later date. Figure 1.3: The RStudio interface with a new script. When writing a script it is important to keep notes about what each step is doing. To do this the hash (#) symbol is put before any code. This comments out that particular line so that R ignores it when the script is run. Type the following into the scripting window: # first attempt at creating a script Some.Data &lt;- data.frame(0:10,20:30) # inspect the result print(Some.Data) Questions Without running these lines of code, what do you expect to happen? Do you understand what these simple line of codes do? In the scripting window if you highlight all the code you have written and press the Run button on the top on the scripting window you will see that the code is sent to the command line and the text on the line after the # is ignored. From now on you should type your code in the scripting window and then use the Run button to execute it. If you have an error then edit the line in the script and hit run again. Try it: # first attempt at creating a script Some.Data &lt;- data.frame(0:10,20:30) print(Some.Data) ## X0.10 X20.30 ## 1 0 20 ## 2 1 21 ## 3 2 22 ## 4 3 23 ## 5 4 24 ## 6 5 25 ## 7 6 26 ## 8 7 27 ## 9 8 28 ## 10 9 29 ## 11 10 30 The My.Data object is a data frame in need of some sensible column headings. You can add these by typing: # add column names names(Some.Data)&lt;- c(&#39;x&#39;,&#39;y&#39;) # print the object to check names were added successfully print(Some.Data) ## x y ## 1 0 20 ## 2 1 21 ## 3 2 22 ## 4 3 23 ## 5 4 24 ## 6 5 25 ## 7 6 26 ## 8 7 27 ## 9 8 28 ## 10 9 29 ## 11 10 30 Until now we have generated the data used in the examples above. One of R’s great strengths is its ability to load in data from almost any file format. Comma Separated Value (csv) files are our preferred choice. These can be thought of as stripped down Excel spreadsheets. They are an extremely simple format so they are easily machine readable and can therefore be easily read in and written out of R. Working Directory Since we are now reading and writing files it is good practice to tell R what your. Your working directory is the folder on the computer where you wish to store the data files you are working with. You can create a folder called POLS0008, for example. If you are using RStudio, on the lower right of the screen is a window with a Files tab. If you click on this tab you can then navigate to the folder you wish to use. You can then click on the More button and then Set as Working Directory. You should then see some code similar to the below appear in the command line. It is also possible to type the code in manually. # set the working directory path to the folder you wish to use # you may need to create the folder first if it doesn&#39;t exist setwd(&#39;~/POLS0008&#39;) # note the single / (\\\\ will also work) Once the working directory is setup it is then possible to load in a csv file. We are going to load a dataset that has been saved in the working directory we just set that shows London’s historic population for each of its Boroughs. You can download the csv file below. File download File Type Link Borough Population London csv Download Once downloaded to your own computer, this file will then need to be uploaded into RStudio. To do this click on the Upload button in the files area of the screen. Select the csv file you just downloaded and press OK. We can then type the following to locate and load in the file we need. # load csv file from working directory London.Pop &lt;- read.csv(&#39;census-historic-population-borough.csv&#39;) To view the object type:s print(London.Pop) ## Area.Code Area.Name Persons.1801 Persons.1811 Persons.1821 ## 1 00AA City of London 129000 121000 125000 ## Persons.1831 Persons.1841 Persons.1851 Persons.1861 Persons.1871 ## 1 123000 124000 128000 112000 75000 ## Persons.1881 Persons.1891 Persons.1901 Persons.1911 Persons.1921 ## 1 51000 38000 27000 20000 14000 ## Persons.1931 Persons.1939 Persons.1951 Persons.1961 Persons.1971 ## 1 11000 9000 5000 4767 4000 ## Persons.1981 Persons.1991 Persons.2001 Persons.2011 Borough.Type ## 1 5864 4230 7181 7375 1 ## [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 32 rows ] Or if you only want to see the top 10 or bottom 10 rows you can use the head() and tail() functions. These are particularly useful if you have large datasets! # view first 10 rows head(London.Pop) ## Area.Code Area.Name Persons.1801 Persons.1811 Persons.1821 ## 1 00AA City of London 129000 121000 125000 ## Persons.1831 Persons.1841 Persons.1851 Persons.1861 Persons.1871 ## 1 123000 124000 128000 112000 75000 ## Persons.1881 Persons.1891 Persons.1901 Persons.1911 Persons.1921 ## 1 51000 38000 27000 20000 14000 ## Persons.1931 Persons.1939 Persons.1951 Persons.1961 Persons.1971 ## 1 11000 9000 5000 4767 4000 ## Persons.1981 Persons.1991 Persons.2001 Persons.2011 Borough.Type ## 1 5864 4230 7181 7375 1 ## [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 5 rows ] # view bottom 10 rows tail(London.Pop) ## Area.Code Area.Name Persons.1801 Persons.1811 Persons.1821 Persons.1831 ## 28 00BE Southwark 116000 139000 175000 207000 ## Persons.1841 Persons.1851 Persons.1861 Persons.1871 Persons.1881 ## 28 243000 292000 346000 407000 514000 ## Persons.1891 Persons.1901 Persons.1911 Persons.1921 Persons.1931 ## 28 572000 596000 579000 571000 535000 ## Persons.1939 Persons.1951 Persons.1961 Persons.1971 Persons.1981 ## 28 456000 338000 313413 262000 211858 ## Persons.1991 Persons.2001 Persons.2011 Borough.Type ## 28 198916 244867 288283 1 ## [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 5 rows ] Depending on the type of object the exact number of lines displayed through head() and tail() may differ. If you want to have precies control over the output and specify how many rows will be printed, you can do this by passing an integer as second argument to either of these functions. For instance, head(London.Pop,n=10) or tail(London.Pop,n=10). To learn a bit more about the file you have loaded, R has a number of useful functions. We can use these to find out how many columns (variables) and rows (cases) the data frame (dataset) contains. ## [1] 25 ## [1] 33 ## [1] &quot;Area.Code&quot; &quot;Area.Name&quot; &quot;Persons.1801&quot; &quot;Persons.1811&quot; ## [5] &quot;Persons.1821&quot; &quot;Persons.1831&quot; &quot;Persons.1841&quot; &quot;Persons.1851&quot; ## [9] &quot;Persons.1861&quot; &quot;Persons.1871&quot; &quot;Persons.1881&quot; &quot;Persons.1891&quot; ## [13] &quot;Persons.1901&quot; &quot;Persons.1911&quot; &quot;Persons.1921&quot; &quot;Persons.1931&quot; ## [17] &quot;Persons.1939&quot; &quot;Persons.1951&quot; &quot;Persons.1961&quot; &quot;Persons.1971&quot; ## [21] &quot;Persons.1981&quot; &quot;Persons.1991&quot; &quot;Persons.2001&quot; &quot;Persons.2011&quot; ## [25] &quot;Borough.Type&quot; Given the number of columns in the pop data frame, subsetting by selecting on the columns of interest would make it easier to handle. In R there are two was of doing this. The first uses the $ symbol to select columns by name and then create a new data frame object. # select the columns containing the Borough names and the 2011 population London.Pop.2011&lt;- data.frame(London.Pop$Area.Name, London.Pop$Persons.2011) # inspect the results head(London.Pop.2011) ## London.Pop.Area.Name London.Pop.Persons.2011 ## 1 City of London 7375 ## 2 Barking and Dagenham 185911 ## 3 Barnet 356386 ## 4 Bexley 231997 ## 5 Brent 311215 ## 6 Bromley 309392 A second approach to selecting particular data is to use [Row, Column] and ‘slice’ the data frame. For instance: # select the 1st row of the 2nd column London.Pop[1,2] ## [1] City of London ## 33 Levels: Barking and Dagenham Barnet Bexley Brent Bromley ... Westminster # select the first 5 rows of the 1st column London.Pop[1:5,1] ## [1] 00AA 00AB 00AC 00AD 00AE ## 33 Levels: 00AA 00AB 00AC 00AD 00AE 00AF 00AG 00AH 00AJ 00AK 00AL ... 00BK # select the first 5 rows of columns 8 to 11 London.Pop[1:5,8:11] ## Persons.1851 Persons.1861 Persons.1871 Persons.1881 ## 1 128000 112000 75000 51000 ## 2 8000 8000 10000 13000 ## 3 15000 20000 29000 41000 ## 4 12000 15000 22000 29000 ## 5 5000 6000 19000 31000 # assign the previous selection to a new object London.Subset &lt;- London.Pop[1:5,8:11] In the code snippet, note how the colon : is used to specify a range of values. We used the same technique to create the Some.Data object above. The ability to select particular columns means we can see how the population of London’s Boroughs have changed over the past century by substracting two columns from one another. # within the brackets you can add additional columns to the data frame # as long as their separated by commas Pop.Change&lt;- data.frame(London.Pop$Area.Name, London.Pop$Persons.2011 - London.Pop$Persons.1911) If you type head(PopChange) you will see that the population change column (created to the right of the comma above) has a very long name. This can be changed using the names() command in the same way as we did this for our Some.Data object. names(Pop.Change)&lt;- c(&#39;Borough&#39;, &#39;Change_1911_2011&#39;) Since we have done some new analysis and created additional information it would be good to save the PopChange object to our working directory as a new csv file. This is done using the code below. Within the brackets we put the name of the R object we wish to save on the left of the comma and the file name on the right of the comma (this needs to be in inverted commas). Remember to put .csv after since this is the file format we are saving in. write.csv(Pop.Change, &#39;Population_Change_1911_2011.csv&#39;) Recap In this section you have learnt how to: Create an R script. Load a csv into R, perform some analysis, and write out a new csv file to your working directory. Subset R data frames by name and also column and/or row number. 1.5 Seminar Seminar assignment Create a csv file that contains the following columns: The names of the London Boroughs. Population change between 1811 and 1911. Population change between 1911 and 1961. Population change 1961 and 2011. Seminar questions Which Boroughs had the fastest growth during the 19th Century, and which had the slowest? You may have noticed that there is an additional column in the pop data frame called Borough-Type. This indicates if a Borough is in inner (1) or outer (2) London. Is this variable ordinal or nominal? 1.6 Before you leave Save your R script by pressing the Save button in the script window. That is it for this week! "],
["examining-data-i.html", "2 Examining data I 2.1 Introduction 2.2 Examining data 2.3 Manipulating data 2.4 Seminar 2.5 Before you leave", " 2 Examining data I 2.1 Introduction Welcome to your second week of Introduction to Quantitative Research Methods. This week we will focus on examining data using descriptive statistics and measures of dispersion. We will also talk about data manipulation and something called metadata. For the tutorial we will continue to use the London.Pop object that we created last week and will use this to create some plots. 2.1.1 Reading list For this week, you will have to read the following book Chapters: Lane et al., 2003, Chapter 2: Graphing Distributions. In: Lane et al., 2003, Introduction to Statistics. Houston, Texas: Rice University. 2.1.2 Video: Overview [Lecture slides] [Watch on MS stream] 2.2 Examining data Any research project involving quantitative data should start with an exploration / examination of the available datasets. This applies both to data that you have collected yourself or data that you have acquired in a different way, e.g. through downloading official UK Census and labour market statistics. The set of techniques that is used to examine your data is called descriptive statistcs. Descriptive statistics are used to describe the basic features of your dataset. Descriptive statistics provide simple summaries about your data. Together with simple visual analysis, they form the basis of virtually every quantitative analysis of data. Visualising data makes it easier to understand, analyse, and communicate. 2.2.1 Video: Descriptive statistics II [Lecture slides] [Watch on MS stream] For this tutorial we will continue to use the London.Pop object that we created during last week’s tutorial. You may still have it loaded into your R workspace. To check if you do you can use the ls() command. Type this into the command line and see if London.Pop is printed. If not you can simply reload it: # set the working directory path to the folder you wish to use # you may need to create the folder first if it doesn&#39;t exist setwd(&#39;~/POLS0008&#39;) # note the single / (\\\\ will also work) If you struggle with setting up your working directory, have a look at how we did this last week! # load csv file from working directory London.Pop &lt;- read.csv(&#39;census-historic-population-borough.csv&#39;) Use the head(), or View() command to remind yourself of the structure of the London population data frame. You should see 25 columns of data. 2.2.2 Plotting data in R Tools to create high quality plots have become one of R’s greatest assets. This is a relatively recent development since the software has traditionally been focused on the statistics rather than visualisation. The standard installation of R has base graphic functionality built in to produce very simple plots. For example we can plot the relationship between the London population in 1811 and 1911. # make a quick plot of two variables of the London population data set plot(London.Pop$Persons.1811,London.Pop$Persons.1911) Questions What happens if you change the order of the variables you put in the plot() function? Why? Instead of using the $ to select the columns of our dataset, how else can we get the same results? The result of calling the plot() function, is a very simple scatter graph. The plot() function offers a huge number of options for customisation. You can see them using the ?plot help pages and also the ?par help pages (par in this case is short for parameters). There are some examples below (note how the parameters come after specifying the x and y columns). # add a title, change point colour, change point size plot(London.Pop$Persons.1811, London.Pop$Persons.1911, main=&#39;Quick Plot in R&#39;, col=&#39;blue&#39;, cex=2) # add a title, change point colour, change point symbol plot(London.Pop$Persons.1811, London.Pop$Persons.1911, main=&quot;Another Quick Plot in R&quot;, col=&#39;magenta&#39;, pch=22) For more information on the plot parameters (some have obscure names) have a look here: http://www.statmethods.net/advgraphs/parameters.html 2.2.3 ggplot2 A slightly different method of creating plots in R requires the ggplot2 package. There are many hundreds of packages in R each designed for a specific purpose. These are not installed automatically, so each one has to be downloaded and then we need to tell R to use it. To download and install the ggplot2 package type the following: If you are running RStudio on your own computer: when you hit enter R could ask you to select a mirror to download the package contents from. It does not really matter which one you choose, but we would suggest you pick the mirror that is geographically closest to you. # install package install.packages(&#39;ggplot2&#39;) The install.packages() step only needs to be performed once. You do not need to install a the package every time you want to use it. However, each time you open R and wish to use a package you need to use the library() command to tell R that it will be required. Figure 2.1: Installing the ggplot2 package. # load ggplot2 package library(ggplot2) The ggplot2 package is an implementation of the Grammar of Graphics (Wilkinson 2005) - a general scheme for data visualisation that breaks up graphs into semantic components such as scales and layers. ggplot2 can serve as a replacement for the base graphics in R and contains a number of default options that match good visualisation practice. You provide the data, tell ggplot2 how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details. Whilst the instructions are step by step. you are encouraged to deviate from them (trying different colours for example) to get a better understanding of what we are doing. For further help, ggplot2 is one of the best documented packages in R and large volumes of documentation are available. Good examples of how to learn how to make great graphs and visualisations can also be found on the website https://cedricscherer.netlify.app/2019/08/05/a-ggplot2-tutorial-for-beautiful-plotting-in-r/. Let’s try to make a basic plot using ggplot2 ourselves. # create a ggplot2 object names &#39;p&#39; p &lt;- ggplot(London.Pop, aes(Persons.1811, Persons.1911)) What you have just done is set up a ggplot object where you say where you want the input data to come from – in this case it is the London.Pop object. The column headings within the aes() brackets refer to the parts of that data frame you wish to use (the variables Persons.1811 and Persons.1911). aes is short for aesthetics that vary – this is a complicated way of saying the data variables used in the plot. If you just type p and hit enter you will get an empty canvas. This is because you have not told ggplot what you want to do with the data. We do this by adding so-called geoms, in this case geom_point(), to create a scatter plot. Let’s try this. # plot p # add our geom to our &#39;p&#39; object p &lt;- p + geom_point() # plot p You can already see that this plot is looking a bit nicer than the one we created with the base plot() function used above. Within the geom_point() brackets you can alter the appearance of the points in the plot. Try something like p + geom_point(colour='red', size=2) and also experiment with your own colours/ sizes. If you want to colour the points according to another variable it is possible to do this by adding the desired variable into the aes() section after geom_point(). Here we will do this to indicate the size of the population in 2011 as well as the relationship between the size of the population in 19811 and 1911. # add some more aesthetics that vary p + geom_point(aes(colour = Persons.2011), size = 2) You will notice that ggplot has also created a key that shows the values associated with each colour. In this slightly contrived example it is also possible to resize each of the points according to the Persons.2011 variable. # add some more aesthetics that vary p + geom_point(aes(size = Persons.2011)) The real power of ggplot2 lies in its ability build a plot up as a series of layers. This is done by stringing plot functions (geoms) together with the + sign. In this case we can add a text layer to the plot using geom_text(). # add some more aesthetics that vary p + geom_point(aes(size = Persons.2011)) + geom_text(size = 2, colour=&#39;red&#39;, aes(label = Area.Name)) This idea of layers (or geoms) is quite different from the standard plot functions in R, but you will find that each of the functions does a lot of clever stuff to make plotting much easier (see the ggplot2 documentation for a full list). The above code adds London Borough labels to the plot over the points they correspond to. This isn’t perfect since many of the labels overlap but they serve as a useful illustration of the layers. To make things a little easier the plot can be saved as a PDF using the ggsave command. When saving the plot can be enlarged to help make the labels more legible. # save the plot ggsave(&#39;first_ggplot.pdf&#39;, scale=2) Questions Where does your plot get saved? Why? ggsave only works with plots that were created with ggplot. Within the brackets you should create a file name for the plot - this needs to include the file format: in this case .pdf, but you could also save the plot as a .jpg file. The file will be saved to your working directory. The scale controls how many times bigger you want the exported plot to be than it currently is in the plot window. Once executed you should be able to see a PDF file in your working directory. Recap In this section you have: Created a scatter plot using the base plot fucntionality in R. Installed and loaded additional packages in R. Learned the basics of the ggplot2 package for creating plots. Learned what geoms are in the context of ggplot2. Learned how to specify data variables with the aes() parameter. Saved your plot. 2.3 Manipulating data 2.3.1 Video: Manipulating data [Lecture slides] [Watch on MS stream] In addition to plotting, descriptive statistics offer a further tool for getting to know your data. They provide useful summaries of a dataset and along with intelligent plotting can also provide a good sanity check to ensure the data conform to expectations. For the rest of this tutorial we will change our dataset to one containing the number of assault incidents that ambulances have been called to in London between 2009 and 2011. You will need to download a revised version of this file called: ambulance_assault.csv and upload it to your working directory. It is in the same data format (csv) as our London population file so we use the read.csv() command again. File download File Type Link Assault Incidents London csv Download # load csv file from working directory input &lt;- read.csv(&#39;ambulance_assault.csv&#39;) # inspect the results head(input) ## Bor_Code WardName WardCode WardType assault_09_11 ## 1 00AA Aldersgate 00AAFA Prospering Metropolitan 10 ## 2 00AA Aldgate 00AAFB Prospering Metropolitan 0 ## 3 00AA Bassishaw 00AAFC Prospering Metropolitan 0 ## 4 00AA Billingsgate 00AAFD Prospering Metropolitan 0 ## 5 00AA Bishopsgate 00AAFE Prospering Metropolitan 188 ## 6 00AA Bread Street 00AAFF Prospering Metropolitan 0 # inspect the size of the dataset nrow(input) ## [1] 649 You will notice that the data table has 4 columns and 649 rows. The column headings are abbreviations of the following: Bor_Code: Borough Code. London has 32 Boroughs (such as Camden, Islington, Westminster, etc.) plus the City of London at the centre. These codes are used as a quick way of referring to them from official data sources. WardName: Boroughs can be broken into much smaller areas known as Wards. These are electoral districts and have existed in London for centuries. WardCode: A statistical code for the Wards above. WardType: a classification that groups wards based on similar characteristics. assault_09_11: The number of assault incidents requiring an ambulance between 2009 and 2011 for each Ward. The mean(), median(), and range() were some of the first R functions we used at the last week to describe our Friends dataset. We will use these to describe our assault incident data as well as other descriptive statistics, including standard deviation. # calculate the mean of the assault incident variable mean(input$assault_09_11) ## [1] 173.4669 # calculate the standard deviation of the assault incident variable sd(input$assault_09_11) ## [1] 130.3482 # calculate the minimum value of the assault incident variable min(input$assault_09_11) ## [1] 0 # calculate the maximum value of the assault incident variable max(input$assault_09_11) ## [1] 1582 # calculate the range of the assault incident variable range(input$assault_09_11) ## [1] 0 1582 These are commonly used descriptive statistics. To make things even easier, R has a summary() function that calculates a number of these routine statistics simultaneously. # calculate the most common descriptive statistics for the assault incident variable summary(input$assault_09_11) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0 86.0 146.0 173.5 233.0 1582.0 You should see you get the minimum (Min.) and maximum (Max.) values of the assault_09_11 column; its first (1st Qu.) and third (3rd Qu.) quartiles that comprise the interquartile range; its the mean and the median. The built-in R summary() function does not calculate the standard deviation. There are functions in other libraries that calculate more detailed descriptive statistics, including describe() in the psych package, which we will use in the later tutorials. We can also use the summary() function to describe a categorical variable and it will list its levels: # summarise a categorical variable summary(input$WardType) ## Accessible Countryside Industrial Hinterlands ## 1 8 ## Multicultural Metropolitan Prospering Metropolitan ## 240 169 ## Student Communities Suburbs and Small Towns ## 9 210 ## Traditional Manufacturing ## 12 As you may notice, the summary of a categorical variable is in very fact the same as frequency table: # create a frequency table of a categorical variable freqtable &lt;- table(input$WardType) # inspect freqtable ## ## Accessible Countryside Industrial Hinterlands ## 1 8 ## Multicultural Metropolitan Prospering Metropolitan ## 240 169 ## Student Communities Suburbs and Small Towns ## 9 210 ## Traditional Manufacturing ## 12 We can also get the proportion of each group using the frequency table as input: # create a frequency table of a categorical variable proptable &lt;- prop.table(freqtable) # inspect proptable ## ## Accessible Countryside Industrial Hinterlands ## 0.001540832 0.012326656 ## Multicultural Metropolitan Prospering Metropolitan ## 0.369799692 0.260400616 ## Student Communities Suburbs and Small Towns ## 0.013867488 0.323574730 ## Traditional Manufacturing ## 0.018489985 2.4 Seminar Seminar assignment Create a histogram plot of the ambulance assaults dataset: Use the ggplot2 package. Instead of the geom_point() geom, use the geom_histogram() geom. Figure out how to change the labels of the x-axis and the y-axis. Save the plot as a pdf. Seminar questions Explain why each of these statistics are useful and what type of data are required to calculate them: Mean Median Mode Interquartile Range Range Standard Deviation 2.5 Before you leave Save your R script by pressing the Save button in the script window. That is it for this week! "],
["examining-data-ii.html", "3 Examining data II 3.1 Introduction 3.2 Examining data 3.3 Visualising data 3.4 Seminar 3.5 Before you leave", " 3 Examining data II 3.1 Introduction Welcome to your third week of Introduction to Quantitative Research Methods. This week we will focus again on examining data, with a particular focus on data visualisation. For the tutorial we will continue to use the asssault incident dataset that we used last week. 3.1.1 Reading list For this week, you will have to read the following book Chapters: Lane et al., 2003, Chapter 3: Summarizing Distributions. In: Lane et al., 2003, Introduction to Statistics. Houston, Texas: Rice University. 3.1.2 Video: Overview [Lecture slides] [Watch on MS stream] 3.2 Examining data 3.2.1 Video: Descriptive statistics III [Lecture slides] [Watch on MS stream] 3.3 Visualising data 3.3.1 Video: Visualising data [Lecture slides] [Watch on MS stream] This week we are picking up where we left off in the previous section. Repeat the opening steps in last weeks practical to reload the input object containing the assault incidents for London. Through plotting we can provide graphical representations of the data to support the statistics above. # load csv file from working directory input &lt;- read.csv(&#39;ambulance_assault.csv&#39;) To simply have the Ward codes on the x-axis and their assault values on the y-axis we need to plot the relevant columns of the input object. # quick plot plot(input$WardCode, input$assault_09_11) 3.3.2 Histograms The basic plot created in the previous step does not look great and it is hard to interpret the raw assault count values. A frequency distribution plot in the form of a histogram will be much better. There are many ways to do this in R but we will use the functions contained within the ggplot2 library. # quick plot using the ggplot2 library p &lt;- ggplot(input, aes(x=assault_09_11)) # inspect p Questions Remember why printing/plotting the p object currently results in an empty canvas? The ggplot(input, aes(x=assault_09_11)) section means “create a generic plot object (called p) from the input object using the assault_09_11 column as the data for the x axis”. Remember the data variables are required as aesthetics parameters so the assault_09_11 appears in the aes() brackets. Histograms provide a nice way of graphically summarising a dataset. To create the histogram you need to add the relevant ggplot2 command (geom). # quick histogram using the ggplot2 library p + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. The height of each bar (the x-axis) shows the count of the datapoints and the width of each bar is the value range of datapoints included. If you want the bars to be thinner (to represent a narrower range of values and capture some more of the variation in the distribution) you can adjust the binwidth. Binwidth controls the size of ‘bins’ that the data are split up into. We will discuss this in more detail later in the course, but put simply, the bigger the bin (larger binwidth) the more data it can hold. Try: # updated histogram using the ggplot2 library p + geom_histogram(binwidth=10) You can also overlay a density distribution over the top of the histogram. Again, this will be discussed in more detail in the coming weeks, but think of the plotted line as a summary of the underlying histogram. For this we need to produce a second plot object that says we wish to use the density distribution as the y variable. # histogram with density distribution using the ggplot2 library p2 &lt;- ggplot(input, aes(x=assault_09_11, y=..density..)) # plot p2 + geom_histogram() + geom_density(fill=NA, colour=&#39;red&#39;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Questions What does the fill parameter do in the above code? This plot has provided a good impression of the overall distribution, but it would be interesting to see characteristics of the data within each of the Boroughs. We can do this since each Borough in the input object is made up of multiple wards. To see what we mean, we can select all the wards that fall within the Borough of Camden, which has the code 00AG (if you want to see what each Borough the code corresponds to, and learn a little more about the statistical geography of England and Wales, then do have a look here. # filter our dataset camden &lt;- input[input$Bor_Code==&#39;00AG&#39;,] The crucial part of the code snippet above is what’s included in the square brackets [ ]. We are subsetting the input object, but instead of telling R what column names or numbers we require, we are requesting all rows in the Bor_Code column that contain 00AG. 00AG is a text string so it needs to go in speech marks '' (or \"\") and we need to use two equals signs == in R to mean “equals to”. A single equals sign = is another way of assigning objects (it works the same way as &lt;- but is much less widley used for this purpose because it is used when paramaterising functions). Let’s quickly compare our original input object with our newly created camden object: # inspect input dataset nrow(input) ## [1] 649 # inspect Camden dataset nrow(camden) ## [1] 18 # inspect Camden dataset head(camden) ## Bor_Code WardName WardCode ## 128 00AG Belsize 00AGGD ## 129 00AG Bloomsbury 00AGGE ## 130 00AG Camden Town with Primrose Hill 00AGGF ## 131 00AG Cantelowes 00AGGG ## 132 00AG Fortune Green 00AGGH ## 133 00AG Frognal and Fitzjohns 00AGGJ ## WardType assault_09_11 ## 128 Prospering Metropolitan 91 ## 129 Prospering Metropolitan 315 ## 130 Prospering Metropolitan 535 ## 131 Multicultural Metropolitan 238 ## 132 Prospering Metropolitan 106 ## 133 Prospering Metropolitan 77 So to produce Camden’s frequency distribution, with the corresponding density distribution, the code above needs to be replicated using the camden object in the place of input: # histogram with density distribution using the ggplot2 library p2.camden &lt;- ggplot(camden, aes(x=assault_09_11, y=..density..)) # plot p2.camden + geom_histogram() + geom_density(fill=NA, colour=&#39;red&#39;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. # plot pretty(ish) p2.camden + geom_histogram() + geom_density(fill=NA, colour=&#39;red&#39;) + ggtitle(&#39;Assault incidents in Camden&#39;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. As you can see this looks a little different from the density of the entire dataset. This is largely becasue we have relatively few rows of data in the camden object (as we saw when using nrow(camden)). Nevertheless it would be interesting to see the data distributions for each of the London Boroughs. It is a chance to use the facet_wrap() function in R. This brilliant function lets you create a whole load of graphs at once! # note that we are back to using the `p` object since we need all our data for this # this code may generate a large number of warning messages relating to the plot binwidth, don&#39;t worry about them p + geom_histogram() + facet_wrap(~Bor_Code) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Yes. It is that easy. Let’s try using facet_wrap() to plot according to Ward type # note that we are back to using the `p` object since we need all our data for this # this code may generate a large number of warning messages relating to the plot binwidth, don&#39;t worry about them p + geom_histogram() + facet_wrap(~WardType) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Questions What are the key differences in the distributions between the different types of our facet_wrap() plots? The facet_wrap() part of the code simply needs the name of the column you would like to use to subset the data into individual plots. Before the column name a tilde ~ is used as shorthand for “by” - so using the function we are asking R to facet the input object into lots of smaller plots based on the Bor_Code column in the first example and WardType in the second. Use the facet_wrap() help file to learn how to create the same plot but with the graphs arranged into 4 columns. 3.3.3 Box and whisker plots In addition to histograms, a type of plot that shows the core characteristics of the distribution of values within a dataset, and includes some of the summary() information we generated earlier, is a box and whisker plot (boxplot for short). These too can be easily produced in R. Figure 3.1: A box and whisker plot. We can create a third plot object for this from the input object: # note that the `assault_09_11` column is now y and not x # we also specified x = 1 to algin the plot to the x-axis (any single number would work) p3 &lt;- ggplot(input, aes(x=1, y=assault_09_11)) # add the boxplot geom p3 + geom_boxplot() If we are just interested in Camden then we can use the camden object created above in the code. # boxplot for camden only p3.camden &lt;- ggplot(camden, aes(x=1, y=assault_09_11)) # add the boxplot geom p3.camden + geom_boxplot() If you prefer you can flip the plot 90 degrees so that it reads from left to right: # boxplot for camden only p3.camden &lt;- ggplot(camden, aes(x=1, y=assault_09_11)) # add the boxplot geom and rotate p3.camden + geom_boxplot() + coord_flip() You can see that Camden looks a little different to the boxplot of the entire dataset. It would therefore be useful to compare the distributions of data within each of the Boroughs in a single plot as we did with the frequency distributions above. ggplot makes this very easy (again!), we just need to change the x parameter to the Borough code column (Bor_Code). # boxplot for camden only p4 &lt;- ggplot(input, aes(x=Bor_Code, y=assault_09_11)) # add the boxplot geom and rotate p4 + geom_boxplot() + coord_flip() Recap In this section you have: Utilised some of the advanced functionality as part of the ggplot2 package, not least through the creation of facetted histogram plots using geom_histogram() and facet_wrap() and also box and whisker plots with geom_boxplot(). Subset data based on a specific criteria (in this case selection the data corresponding to Camden). Explored the distribution of dataset through histograms, density and boxplots. 3.4 Seminar Seminar assignment Take the census-historic-population-borough.csv file we used to produce the scatter plots of London’s population in Week 01 and create 3 different types of plots from one or more of the variables. 3.5 Before you leave Save your R script by pressing the Save button in the script window. That is it for this week! "],
["sourcing-data.html", "4 Sourcing data", " 4 Sourcing data This week’s content will be made on 01/02. "]
]
